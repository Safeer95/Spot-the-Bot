{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cfe5c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Word documents: 1381\n",
      "Number of documents after combining: 1382\n"
     ]
    }
   ],
   "source": [
    "import docx2txt\n",
    "import os\n",
    "\n",
    "# specify the directory where your Word files are stored\n",
    "path = 'D:/Spot The Bot Data/Persian/Word files/All'\n",
    "\n",
    "# create an empty list to store the text from each file\n",
    "text_list = []\n",
    "\n",
    "# loop through each file in the directory, extract the text using docx2txt, and append it to the text_list\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.docx'):\n",
    "        file_path = os.path.join(path, filename)\n",
    "        text = docx2txt.process(file_path)\n",
    "        text_list.append(text.strip().replace('\\n', ' ')) # replace newlines with space\n",
    "        text_list.append('^^^^^^')\n",
    "\n",
    "# write the text from the text_list to a text file\n",
    "with open('combined_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(text_list))\n",
    "\n",
    "# read the combined text and split it into individual documents\n",
    "with open('combined_text.txt', 'r', encoding='utf-8') as f:\n",
    "    combined_text = f.read()\n",
    "\n",
    "documents = combined_text.split('^^^^^^')\n",
    "\n",
    "print('Number of Word documents:', num_documents)\n",
    "print('Number of documents after combining:', len(documents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700214e5",
   "metadata": {},
   "source": [
    "The actuall number of texts here is 2000. It is just because when converting pdf files to  word files we sometimes combined more than one pdf file in one word file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a914bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import docx\n",
    "\n",
    "\n",
    "# # Set the directory where the Word files are located\n",
    "# directory = \"D:/Spot The Bot Data/Word files/All\"\n",
    "\n",
    "# # Get all the Word files in the directory\n",
    "# word_files = glob.glob(os.path.join(directory, \"*.docx\"))\n",
    "\n",
    "# # Open a new text file to write the combined text\n",
    "# with open(\"combined_text.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     # Loop through each Word file\n",
    "#     for word_file in word_files:\n",
    "#         # Load the Word file using the docx library\n",
    "#         doc = docx.Document(word_file)\n",
    "#         # Loop through each paragraph in the Word file and write it to the text file\n",
    "#         for para in doc.paragraphs:\n",
    "#             f.write(para.text)\n",
    "#             f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1b2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
