{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUAswexxWBei"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vectorizer():\n",
        "    def __init__(self, corp_path):\n",
        "        self.corp_path = corp_path\n",
        "    \n",
        "    def upload_corp(self):\n",
        "        with open(self.corp_path, 'r', encoding='utf-8') as f:\n",
        "            self.corp = list(set(f.read().split('\\n')[:-1]))\n",
        "        \n",
        "        self.corp = [text.replace(',', ' ') for text in self.corp]\n",
        "    \n",
        "    \n",
        "    def log(self, part):\n",
        "        clear_output(wait=True)\n",
        "        print(f'{part} is processing')\n",
        "        \n",
        "    def make_tf_idf_matrix(self, token_pattern=None):\n",
        "        if token_pattern:\n",
        "            self.tfidf = TfidfVectorizer(token_pattern=token_pattern)\n",
        "        else:\n",
        "            self.tfidf = TfidfVectorizer()\n",
        "            \n",
        "        self.A = self.tfidf.fit_transform(self.corp)\n",
        "        self.feature_list = self.tfidf.get_feature_names_out()\n",
        "        \n",
        "    def make_svd(self, n=30):\n",
        "        self.u, self.sigma, self.vT = svds(self.A, n)\n",
        "        self.singular_indicies = np.argsort(-self.sigma)\n",
        "        \n",
        "        self.u = self.u[:, self.singular_indicies]\n",
        "        self.sigma = np.diag(self.sigma[self.singular_indicies])\n",
        "        self.vT = self.vT[self.singular_indicies, :]\n",
        "        \n",
        "        self.embedded_matrix = self.sigma@self.vT\n",
        "        \n",
        "        self.words_embedding_dict = dict(zip(self.feature_list, self.embedded_matrix.T))\n",
        "    \n",
        "    def get_emb_dict(self):\n",
        "        \n",
        "        self.log('Upload')\n",
        "        self.upload_corp()\n",
        "        self.log('TfIdf')\n",
        "        self.make_tf_idf_matrix()\n",
        "        self.log('SVD')\n",
        "        self.make_svd(n=20)\n",
        "        \n",
        "        return self.words_embedding_dict"
      ],
      "metadata": {
        "id": "qgVK4wJvWLPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = Vectorizer('/content/persian_cleaned_corpus.txt')\n",
        "emb_dict = vect.get_emb_dict()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWlBJl66WjjK",
        "outputId": "e66242b3-2f9a-4578-90b6-031b665b4bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD is processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Select 20 random keys from the embedding dictionary\n",
        "keys = random.sample(emb_dict.keys(), 20)\n",
        "\n",
        "# Print the embeddings of the selected keys, rounded to 4 decimal places\n",
        "for k in keys:\n",
        "    print(f'{k}: {emb_dict[k].round(4)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCg5_A2rZQW1",
        "outputId": "ffc244fd-d7ba-4fb3-a32b-c77367d18ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "میکنیمر: [ 0.0001  0.      0.0001 -0.0002  0.     -0.      0.     -0.      0.0001\n",
            " -0.0001  0.     -0.0001  0.      0.     -0.      0.      0.      0.\n",
            "  0.      0.0001]\n",
            "بندآخر: [ 0.0004 -0.0001  0.     -0.0003  0.0002 -0.0001  0.0001  0.0002 -0.0003\n",
            " -0.0002 -0.0003  0.0002  0.0002  0.     -0.0001  0.0001  0.      0.0001\n",
            "  0.0003  0.0001]\n",
            "مندیگک: [ 0.0003  0.0001 -0.0005  0.0002 -0.      0.0004 -0.0001 -0.0002 -0.0001\n",
            " -0.0002  0.      0.      0.     -0.      0.     -0.0001  0.      0.\n",
            "  0.     -0.    ]\n",
            "ابدیزد: [ 0.0001 -0.     -0.      0.0001  0.     -0.      0.0001  0.      0.\n",
            " -0.     -0.     -0.     -0.0001  0.     -0.      0.      0.      0.\n",
            " -0.0001 -0.    ]\n",
            "گزپن: [ 0.0003 -0.0001  0.     -0.0002  0.0001 -0.      0.     -0.0001 -0.0001\n",
            " -0.     -0.0001  0.     -0.0001 -0.0001  0.     -0.      0.0001 -0.0001\n",
            "  0.0001 -0.0003]\n",
            "برایبتلاشدن: [ 0.0002 -0.0001  0.     -0.     -0.0002 -0.0001  0.     -0.      0.\n",
            "  0.     -0.0001  0.     -0.      0.     -0.0001  0.      0.      0.\n",
            " -0.0001  0.    ]\n",
            "اولسرهنگ: [ 0.0001  0.      0.0001  0.0002  0.0002 -0.0001 -0.0001 -0.      0.0001\n",
            "  0.     -0.     -0.0002  0.0002  0.      0.0001  0.     -0.0001  0.0002\n",
            "  0.     -0.    ]\n",
            "گرادوستاج: [ 0.0001 -0.0001  0.     -0.0001  0.0002  0.0002 -0.0003  0.0002 -0.0001\n",
            " -0.      0.0002 -0.0002 -0.      0.     -0.0001 -0.     -0.     -0.0001\n",
            "  0.0001 -0.0001]\n",
            "نیفتادهاس: [ 0.0006 -0.0002  0.0005 -0.     -0.0003  0.     -0.0008 -0.0005  0.0012\n",
            "  0.0003  0.0007  0.0002 -0.0005 -0.0007  0.0008 -0.0004  0.     -0.0001\n",
            "  0.0001  0.    ]\n",
            "منسوبا: [ 0.0004 -0.0001 -0.0001 -0.0006  0.0001  0.0003  0.0005  0.0009 -0.0001\n",
            "  0.0008  0.0005  0.0005  0.0004  0.0001 -0.0002 -0.0003 -0.0004 -0.0004\n",
            " -0.0014 -0.0002]\n",
            "باخانوادة: [ 0.0001 -0.      0.0001 -0.     -0.0001 -0.0001  0.0001 -0.      0.0002\n",
            "  0.     -0.     -0.      0.      0.      0.      0.     -0.     -0.0001\n",
            " -0.     -0.    ]\n",
            "الیمن: [ 0.0011  0.     -0.0003 -0.0002 -0.      0.0002  0.0003  0.0003  0.0002\n",
            "  0.0002 -0.0007 -0.0002  0.001   0.0002  0.0003 -0.0002 -0.001   0.001\n",
            " -0.0005  0.0002]\n",
            "بچگوته: [ 0.0003 -0.0002  0.0002 -0.0001 -0.0002 -0.0003 -0.0001 -0.0004 -0.0003\n",
            "  0.     -0.0003  0.0001  0.0001 -0.      0.     -0.      0.0001 -0.0001\n",
            "  0.0003 -0.0003]\n",
            "بیرونبرخطا: [ 0.0005  0.0001  0.     -0.001   0.0002 -0.0001  0.0007  0.0003  0.0006\n",
            " -0.001   0.0004 -0.0002  0.0002  0.0004 -0.0005 -0.      0.0002  0.0001\n",
            "  0.0002  0.0011]\n",
            "ایسسمن: [ 0.0002 -0.      0.     -0.0001  0.0001 -0.     -0.      0.     -0.0001\n",
            " -0.      0.      0.      0.     -0.      0.     -0.     -0.      0.\n",
            "  0.     -0.    ]\n",
            "چسوب: [ 0.0006 -0.0002 -0.     -0.0006  0.0002  0.0001  0.0001  0.0005 -0.0002\n",
            "  0.0002 -0.0002  0.0004  0.0002  0.     -0.0002  0.0001 -0.0001  0.\n",
            " -0.0001  0.0002]\n",
            "پجرخه: [ 0.0001  0.     -0.      0.0001  0.     -0.     -0.     -0.      0.\n",
            "  0.      0.      0.     -0.     -0.      0.     -0.     -0.      0.\n",
            "  0.      0.    ]\n",
            "میکنندکورو: [ 0.0004 -0.0001  0.     -0.0003  0.0002 -0.0001  0.0001  0.0002 -0.0003\n",
            " -0.0002 -0.0003  0.0002  0.0002  0.     -0.0001  0.0001  0.      0.0001\n",
            "  0.0003  0.0001]\n",
            "ترقیوتنزل: [ 0.0004 -0.0003 -0.0002  0.0006  0.0001 -0.      0.0009  0.0009 -0.0001\n",
            "  0.0013  0.0011  0.0002 -0.0008 -0.0001  0.0004  0.0005  0.0006  0.0002\n",
            "  0.0015  0.0005]\n",
            "سراماء: [ 0.0004  0.0003  0.0002 -0.0012  0.0004 -0.0004  0.0005 -0.0003 -0.0003\n",
            " -0.0004  0.0004  0.0001 -0.0001  0.0002 -0.0005  0.      0.0003  0.\n",
            "  0.0003  0.    ]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-ffabcaae2cef>:4: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  keys = random.sample(emb_dict.keys(), 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Convert numpy arrays to lists in the emb_dict dictionary\n",
        "emb_dict = {k: emb_dict[k].tolist() for k in emb_dict}\n",
        "\n",
        "# Save the emb_dict dictionary to a file\n",
        "with open('emb_dict.json', 'w') as f:\n",
        "    json.dump(emb_dict, f)"
      ],
      "metadata": {
        "id": "rNzfWSkXf2Xq"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0CUcPgsffdUL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}