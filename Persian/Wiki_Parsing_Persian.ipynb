{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kG_hidR1rbv",
        "outputId": "d9de4598-fbcf-4e11-9552-1d2082e140de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import time\n",
        "\n",
        "# function to extract text from a Wikipedia URL\n",
        "def extract_text(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    text = soup.find('div', {'class': 'mw-parser-output'}).get_text()\n",
        "    return text\n",
        "\n",
        "# initialize lists to store URLs and text\n",
        "urls = []\n",
        "text_list = []\n",
        "\n",
        "# number of batches to fetch\n",
        "batches = 500\n",
        "\n",
        "# fetch URLs and text in batches\n",
        "for i in range(batches):\n",
        "    # send request to the Wikipedia API\n",
        "    response = requests.get(f'https://fa.wikipedia.org/w/api.php?action=query&list=random&rnnamespace=0&rnlimit=500&format=json')\n",
        "    data = response.json()\n",
        "\n",
        "    # extract URLs from the API response\n",
        "    for item in data['query']['random']:\n",
        "        url = f'https://fa.wikipedia.org/wiki?curid={item[\"id\"]}'\n",
        "        urls.append(url)\n",
        "\n",
        "    # extract text from the URLs\n",
        "    for url in urls:\n",
        "        text = extract_text(url)\n",
        "        text_list.append(text)\n",
        "\n",
        "    # save the URLs and text to a file\n",
        "    with open('/content/drive/MyDrive/Spot the bot project/data.json', 'w') as f:\n",
        "        json.dump({'text': text_list}, f)\n",
        "    print(f'Batch {i} saved to data.json')\n",
        "    # wait for 5 seconds before making the next API request\n",
        "    time.sleep(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M70BUG7_1tS1",
        "outputId": "7a926727-0706-4ba8-a55b-17ef9f6ce713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0 saved to data.json\n",
            "Batch 1 saved to data.json\n",
            "Batch 2 saved to data.json\n",
            "Batch 3 saved to data.json\n",
            "Batch 4 saved to data.json\n",
            "Batch 5 saved to data.json\n",
            "Batch 6 saved to data.json\n",
            "Batch 7 saved to data.json\n",
            "Batch 8 saved to data.json\n",
            "Batch 9 saved to data.json\n",
            "Batch 10 saved to data.json\n",
            "Batch 11 saved to data.json\n",
            "Batch 12 saved to data.json\n",
            "Batch 13 saved to data.json\n",
            "Batch 14 saved to data.json\n",
            "Batch 15 saved to data.json\n",
            "Batch 16 saved to data.json\n",
            "Batch 17 saved to data.json\n",
            "Batch 18 saved to data.json\n",
            "Batch 19 saved to data.json\n",
            "Batch 20 saved to data.json\n",
            "Batch 21 saved to data.json\n",
            "Batch 22 saved to data.json\n",
            "Batch 23 saved to data.json\n",
            "Batch 24 saved to data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# open the JSON file\n",
        "with open('/content/drive/MyDrive/Spot the bot project/data.json', 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# create an empty list to store the text\n",
        "dirty_text = []\n",
        "\n",
        "# add the text to the list\n",
        "for text in data['text']:\n",
        "    dirty_text.append(text)"
      ],
      "metadata": {
        "id": "KMCMsX7W2O5O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dirty_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZP6DGqd2ayQ",
        "outputId": "e5257ff4-2f3a-4301-9da6-cc34c587e4ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162500"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}