{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RQwVVw5YNuQb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOHEb9ZDP8it",
        "outputId": "2e5fa8fc-2144-4264-dbe2-f5d4567a6219"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Vectorizer():\n",
        "    def __init__(self, corp_path):\n",
        "        self.corp_path = corp_path\n",
        "    \n",
        "    def upload_corp(self):\n",
        "        with open(self.corp_path, 'r') as f:\n",
        "            self.corp = list(set(f.read().split('\\n')[:-1]))\n",
        "        \n",
        "        self.corp = [text.replace(',', ' ') for text in self.corp]\n",
        "    \n",
        "    \n",
        "    def log(self, part):\n",
        "        clear_output(wait=True)\n",
        "        print(f'{part} is processing')\n",
        "        \n",
        "    def make_tf_idf_matrix(self, token_pattern=None):\n",
        "        if token_pattern:\n",
        "            self.tfidf = TfidfVectorizer(token_pattern=token_pattern)\n",
        "        else:\n",
        "            self.tfidf = TfidfVectorizer()\n",
        "            \n",
        "        self.A = self.tfidf.fit_transform(self.corp)\n",
        "        self.feature_list = self.tfidf.get_feature_names_out()\n",
        "        \n",
        "    def make_svd(self, n=30):\n",
        "        self.u, self.sigma, self.vT = svds(self.A, n)\n",
        "        self.singular_indicies = np.argsort(-self.sigma)\n",
        "        \n",
        "        self.u = self.u[:, self.singular_indicies]\n",
        "        self.sigma = np.diag(self.sigma[self.singular_indicies])\n",
        "        self.vT = self.vT[self.singular_indicies, :]\n",
        "        \n",
        "        self.embedded_matrix = self.sigma@self.vT\n",
        "        \n",
        "        self.words_embedding_dict = dict(zip(self.feature_list, self.embedded_matrix.T))\n",
        "    \n",
        "    def get_emb_dict(self):\n",
        "        \n",
        "        self.log('Upload')\n",
        "        self.upload_corp()\n",
        "        self.log('TfIdf')\n",
        "        self.make_tf_idf_matrix()\n",
        "        self.log('SVD')\n",
        "        self.make_svd(n=20)\n",
        "        \n",
        "        return self.words_embedding_dict"
      ],
      "metadata": {
        "id": "sTBksbuAPyTc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Spot the Bot/Wiki-Files/stemmed_no_stopwords_corpus.json\", 'r') as f:\n",
        "        clean_corp = json.load(f)"
      ],
      "metadata": {
        "id": "HXj5q6ahTP63"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(clean_corp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDnYTNZLT6HS",
        "outputId": "5a06892c-535d-444d-9fd0-b611259b60a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "596137"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('corpus.txt', 'w') as f:\n",
        "    for text in clean_corp:\n",
        "        f.write(text + '\\n')"
      ],
      "metadata": {
        "id": "FTbCyPkVc6jP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = Vectorizer('corpus.txt')"
      ],
      "metadata": {
        "id": "KqR-B6Y-QIpQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_dict = vect.get_emb_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLH-AmRBcXeD",
        "outputId": "cfbb1f15-7bcc-4325-8888-84bfab751ec0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVD is processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for c, k in enumerate(emb_dict.keys()):\n",
        "    print(f'{k}: ', emb_dict[k].round(4))\n",
        "    if c == 20:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4qVn_5mbxBb",
        "outputId": "1405851f-eaed-434c-f288-3e099adb4048"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ءامنوا:  [-0.     -0.0001 -0.0001  0.      0.     -0.     -0.0001 -0.     -0.0001\n",
            "  0.0001  0.0002  0.      0.     -0.      0.0001  0.0001  0.      0.\n",
            " -0.     -0.    ]\n",
            "ءفیزیکی:  [-0. -0. -0.  0.  0.  0. -0.  0. -0.  0.  0. -0.  0. -0.  0.  0.  0. -0.\n",
            " -0. -0.]\n",
            "آآ:  [-0.0029 -0.006  -0.0032 -0.0007  0.0056  0.0023 -0.0012  0.0296  0.007\n",
            " -0.0048  0.0039  0.0001  0.     -0.0013  0.0016  0.0027  0.0067  0.0005\n",
            "  0.0007 -0.001 ]\n",
            "آآرآرسی:  [-0.0001 -0.0002 -0.0002 -0.0001  0.0001  0.     -0.0001 -0.0001 -0.0001\n",
            "  0.0001  0.0004  0.0002  0.0001 -0.0002  0.0001  0.0001  0.0001  0.0001\n",
            " -0.0003 -0.    ]\n",
            "آآروی:  [-0.0001 -0.0002 -0.0002  0.0001  0.     -0.0001 -0.0001 -0.     -0.0002\n",
            "  0.0002  0.0004  0.0001 -0.0002 -0.0001  0.0001  0.0001  0.0001 -0.0001\n",
            " -0.0001 -0.0001]\n",
            "آآمدده:  [-0.     -0.0001 -0.0001  0.      0.0001  0.     -0.0001 -0.     -0.0001\n",
            "  0.0001  0.0001 -0.      0.     -0.0001  0.      0.     -0.     -0.\n",
            " -0.     -0.0001]\n",
            "آئاسی:  [-0.0001 -0.0002 -0.0002  0.      0.0002 -0.      0.     -0.0001 -0.\n",
            " -0.0002  0.0004  0.0001  0.0001 -0.0001  0.0001  0.0001 -0.0001 -0.\n",
            " -0.0001 -0.0001]\n",
            "آئتیوس:  [-0.0001 -0.0002 -0.0002  0.      0.0002  0.     -0.0002 -0.     -0.0002\n",
            "  0.0004  0.0005  0.0001  0.0002  0.      0.0002  0.0002  0.     -0.\n",
            " -0.     -0.0003]\n",
            "آئدس:  [-0.0001 -0.0001 -0.0001  0.      0.0001  0.     -0.0001  0.     -0.0002\n",
            "  0.0001  0.0003  0.      0.     -0.0002  0.      0.0001  0.     -0.\n",
            " -0.0001 -0.0002]\n",
            "آئدسیا:  [-0.     -0.     -0.      0.      0.      0.     -0.0001  0.     -0.0001\n",
            "  0.0001  0.0001  0.      0.0001  0.0001 -0.      0.0001  0.      0.\n",
            " -0.     -0.0001]\n",
            "آئدسیوس:  [-0.     -0.     -0.      0.      0.      0.     -0.0001  0.     -0.0001\n",
            "  0.0001  0.0001  0.      0.0001  0.0001 -0.      0.0001  0.      0.\n",
            " -0.     -0.0001]\n",
            "آئدو:  [-0.0001 -0.0001 -0.0001  0.      0.0001 -0.0001  0.0001  0.     -0.0001\n",
            "  0.0001  0.0001  0.      0.     -0.0001 -0.     -0.     -0.0002 -0.0001\n",
            "  0.     -0.0001]\n",
            "آئر:  [-0.0004 -0.0009 -0.001   0.0007  0.0004 -0.0001 -0.0006 -0.     -0.0011\n",
            "  0.0008  0.0018 -0.      0.0003 -0.0006  0.0007  0.0004 -0.0003 -0.0001\n",
            " -0.0003 -0.0011]\n",
            "آئرئا:  [-0.0005 -0.0007 -0.0005 -0.0003  0.0006  0.      0.0002 -0.0002  0.0005\n",
            " -0.001   0.0014  0.0002  0.0003  0.0004 -0.0008 -0.0016 -0.0011 -0.0004\n",
            "  0.0004 -0.0002]\n",
            "آئرئاس:  [-0.0003 -0.0004 -0.0003 -0.0001  0.0004  0.      0.0002 -0.0002  0.0002\n",
            " -0.0007  0.0011  0.0006  0.0003 -0.0003 -0.0003 -0.0014 -0.0008 -0.0005\n",
            "  0.001   0.0001]\n",
            "آئرئوتوی:  [-0.0002 -0.0004 -0.0004 -0.0001  0.0004  0.      0.0001 -0.0002  0.0003\n",
            " -0.0007  0.001   0.0001  0.0002  0.0001 -0.0004 -0.0008 -0.0006 -0.0002\n",
            "  0.0003 -0.0001]\n",
            "آئرئوس:  [-0.0004 -0.0006 -0.0006 -0.0002  0.0006 -0.      0.0004 -0.0002  0.0004\n",
            " -0.0012  0.0015  0.0002  0.0003  0.0003 -0.001  -0.0016 -0.0012 -0.0005\n",
            "  0.0006 -0.0003]\n",
            "آئرله:  [-0.0006  0.0001  0.     -0.      0.      0.      0.     -0.0001  0.0001\n",
            "  0.     -0.0001  0.0002  0.     -0.0001  0.0001  0.      0.     -0.0001\n",
            "  0.0003 -0.0001]\n",
            "آئرن:  [-0.     -0.0001 -0.0001 -0.0001  0.0001 -0.      0.0002 -0.0004  0.0002\n",
            " -0.0016  0.0016  0.0001  0.0002  0.0001 -0.0003 -0.0015 -0.0002 -0.0002\n",
            "  0.0006  0.0001]\n",
            "آئرو:  [-0.0027 -0.0048 -0.0041 -0.0002  0.003   0.0011  0.0011  0.0005  0.0003\n",
            " -0.001   0.0028  0.0017  0.0007  0.0013 -0.004  -0.0039 -0.0074 -0.0019\n",
            "  0.0004 -0.0009]\n",
            "آئرواستار:  [-0.     -0.     -0.      0.      0.     -0.     -0.     -0.     -0.\n",
            "  0.      0.      0.     -0.0001  0.      0.      0.      0.     -0.\n",
            " -0.     -0.    ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(emb_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J8-riAQdoxc",
        "outputId": "2c4c3dcf-a21c-4dac-e0a3-96fd418d0985"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "279005"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vect.vT[1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onqJlYa9dRpt",
        "outputId": "fe06760c-efbc-40f9-95f9-d8a6cc53644d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "279005"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AgFNBYjIdxbu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}